Bug type,Commit Message
add init_adapters_config method,Separate adapters config from model config (#31)
move padding_mask to modeling_llama.py,Upgrade Transformers to v4.38.x (#654)
add init_adapters_config method,Separate adapters config from model config (#31)
fix bug in test_adapter_backward_compability,Remove deprecated functionality (#714)
add use_safetensors argument to modeladaptersmixin,Support saving & loading via Safetensors (#692)
add static cache to mistral modeling mistral,Upgrade Transformers to v4.42.x (#719)
fix typos in distilbert/mixin_distilbert.py,Separate adapters config from model config (#31)
fix bug in bertselfoutputadaptersmixin,Separate adapters config from model config (#31)
add prefix_tuning_layer and prefix_tuning_layer,Refactor adapter composition implementation (#591)
fix debertaselfattentionadaptersmixin.init_adapters,Separate adapters config from model config (#31)
add more examples to run_generation.py,Fix import error for Huggingface-hub version >=0.26.0 & Update Notebooks (#750)
fix typo in `forwardcontext.wrapper_func`,Separate adapters config from model config (#31)
update transformers.utils.versions.py to v4.44.0,Fix import error for Huggingface-hub version >=0.26.0 & Update Notebooks (#750)
fix typo in modeling_beit.py,Refactor adapter composition implementation (#591)
fix code style in tests/methods/base.py,Remove deprecated functionality (#714)
